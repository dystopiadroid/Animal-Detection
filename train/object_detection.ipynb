{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "object_detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IM0LGFen-Ko1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mA8NpNdKXJUh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install 'tensorflow==1.14.0'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59GW17NDXnvP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow\n",
        "tensorflow.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZJBcIrq4K-7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy\n",
        "numpy.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnya2MJP-EEP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install numpy===1.16.4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjHtPOvUfKnu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "# Things to change:\n",
        "NUM_TRAIN_STEPS = 5000\n",
        "# MODEL_TYPE = 'ssd_mobilenet_v1_quantized_300x300_coco14_sync_2018_07_18'\n",
        "# CONFIG_TYPE = 'ssd_mobilenet_v1_quantized_300x300_coco14_sync'\n",
        "\n",
        "MODEL_TYPE = 'ssd_mobilenet_v2_coco_2018_03_29'\n",
        "CONFIG_TYPE = 'ssd_mobilenet_v2_coco'\n",
        "################################################################################\n",
        "\n",
        "import os\n",
        "GOOGLE_DRIVE_MOUNT    = '/content/drive'\n",
        "CHECKPOINT_PATH = '/content/checkpoint'\n",
        "OUTPUT_PATH     = '/content/output'\n",
        "EXPORTED_PATH   = '/content/exported'\n",
        "DATA_PATH       = '/content/drive/My Drive/data'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTHWPYmtfUC3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "!cd /content\n",
        "!git clone --depth=1 https://github.com/tensorflow/models.git\n",
        "!pip install --no-deps tensorflowjs==1.4.0\n",
        "\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "pwd = os.getcwd()\n",
        "os.environ['PYTHONPATH'] += f':{pwd}:{pwd}/slim'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-WavcOCfWoF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test Setup\n",
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCg97fEzfbFt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(GOOGLE_DRIVE_MOUNT)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siRNKiuvsz25",
        "colab_type": "text"
      },
      "source": [
        "# Generate TFRecords\n",
        "The TensorFlow Object Detection API expects our data to be in the format of TFRecords.\n",
        "\n",
        "The TFRecord format is a collection of serialized feature dicts, one for each image, looking something like this:\n",
        "```\n",
        "{\n",
        "  'image/height': 1800,\n",
        "  'image/width': 2400,\n",
        "  'image/filename': 'image1.jpg',\n",
        "  'image/source_id': 'image1.jpg',\n",
        "  'image/encoded': ACTUAL_ENCODED_IMAGE_DATA_AS_BYTES,\n",
        "  'image/format': 'jpeg',\n",
        "  'image/object/bbox/xmin': [0.7255949630314233, 0.8845598428835489],\n",
        "  'image/object/bbox/xmax': [0.9695875693160814, 1.0000000000000000],\n",
        "  'image/object/bbox/ymin': [0.5820120073891626, 0.1829972290640394],\n",
        "  'image/object/bbox/ymax': [1.0000000000000000, 0.9662484605911330],\n",
        "  'image/object/class/text': (['Cat', 'Dog']),\n",
        "  'image/object/class/label': ([1, 2])\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9OiSBiUiYPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LABEL_MAP_PATH    = os.path.join(DATA_PATH, 'label_map.pbtxt')\n",
        "TRAIN_RECORD_PATH = os.path.join(DATA_PATH, 'train.record')\n",
        "VAL_RECORD_PATH   = os.path.join(DATA_PATH, 'val.record')\n",
        "\n",
        "MY_DRIVE = '/content/drive/My Drive/'\n",
        "classes_file = MY_DRIVE + 'OIDv4_ToolKit/classes.txt'\n",
        "class_descriptions_file = MY_DRIVE + 'OIDv4_ToolKit/OID/csv_folder/class-descriptions-boxable.csv'\n",
        "annotations_file = MY_DRIVE + 'OIDv4_ToolKit/OID/csv_folder/train-annotations-bbox.csv'\n",
        "images_dir = MY_DRIVE + 'OIDv4_ToolKit/OID/Dataset/train'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2q7xoIcgn2OG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Write names of classes in rows\n",
        "\n",
        "#### classes.txt Example\n",
        "Apple\n",
        "Orange\n",
        "Light switch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXoDHbt-fmr0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "# Get a list of labels from the annotations.json\n",
        "labels = {}\n",
        "classes = list(filter(None, open(classes_file).read().split('\\n')))\n",
        "\n",
        "classes = {name: idx + 1 for idx, name in enumerate(classes)}\n",
        "print(f'Classes: {classes}')\n",
        "\n",
        "# labels = {'Tiger', 'Giraffe', 'Elephant', 'Lion', 'Monkey'}\n",
        "\n",
        "# Create a file named label_map.pbtxt\n",
        "os.makedirs(DATA_PATH, exist_ok=True)\n",
        "with open(LABEL_MAP_PATH, 'w') as f:\n",
        "  # Loop through all of the labels and write each label to the file with an id\n",
        "  for idx, label in enumerate(classes):\n",
        "    f.write('item {\\n')\n",
        "    f.write(\"\\tname: '{}'\\n\".format(label))\n",
        "    f.write('\\tid: {}\\n'.format(idx + 1)) # indexes must start at 1\n",
        "    f.write('}\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNlclkp7gBIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "classes = list(filter(None, open(classes_file).read().split('\\n')))\n",
        "classes = {name: idx + 1 for idx, name in enumerate(classes)}\n",
        "print(f'Classes: {classes}')\n",
        "\n",
        "class_descriptions = {row[0]: row[1] for _, row in pd.read_csv(class_descriptions_file, header=None).iterrows()}\n",
        "\n",
        "annotations = pd.read_csv(annotations_file)\n",
        "annotations['LabelName'] = annotations['LabelName'].map(lambda n: class_descriptions[n])\n",
        "annotations = annotations.groupby('ImageID')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29kH2Kt3DoTT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import io\n",
        "import json\n",
        "import random\n",
        "\n",
        "from PIL import Image\n",
        "import PIL.Image\n",
        "import tensorflow as tf\n",
        "\n",
        "from object_detection.utils import dataset_util\n",
        "from object_detection.utils import label_map_util\n",
        "\n",
        "\n",
        "def create_tf_record(images, label_map, output_file):\n",
        "  images = map(lambda i: (os.path.basename(i).split('.jpg')[0], i), images)\n",
        "  images = dict(images)\n",
        "  print(f'{len(images)} images')\n",
        "  writer = tf.python_io.TFRecordWriter(output_file)\n",
        "  count = 0\n",
        "  for image_id, path in images.items():\n",
        "    try:\n",
        "      count = count + 1\n",
        "      img_width, img_height = Image.open(path).size\n",
        "      img_data = tf.gfile.GFile(path, 'rb').read()\n",
        "\n",
        "      xmins = []\n",
        "      xmaxs = []\n",
        "      ymins = []\n",
        "      ymaxs = []\n",
        "      classes_text = []\n",
        "      classes_int = []\n",
        "      # Read in the image.\n",
        "      with tf.gfile.GFile(path, 'rb') as fid:\n",
        "        encoded_jpg = fid.read()\n",
        "\n",
        "      # Open the image with PIL so we can check that it's a jpeg and get the image\n",
        "      # dimensions.\n",
        "      encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
        "      image = PIL.Image.open(encoded_jpg_io)\n",
        "      if image.format != 'JPEG':\n",
        "        raise ValueError('Image format not JPEG')\n",
        "\n",
        "      image_annotations = annotations.get_group(image_id)\n",
        "      for _, row in image_annotations.loc[image_annotations['LabelName'].isin(classes.keys())].iterrows():\n",
        "          xmins.append(row['XMin'])\n",
        "          xmaxs.append(row['XMax'])\n",
        "          ymins.append(row['YMin'])\n",
        "          ymaxs.append(row['YMax'])\n",
        "          classes_text.append(row['LabelName'].encode('utf8'))\n",
        "          classes_int.append(label_map[row['LabelName']])\n",
        "\n",
        "      if (img_width < 50 or img_height < 50  or (xmaxs[0] - xmins[0]) / (ymaxs[0] - ymins[0]) < 0.2 or (xmaxs[0] - xmins[0]) / (ymaxs[0] - ymins[0]) > 5.):\n",
        "        raise AssertionError('Wrong dimensions')\n",
        "      # Create the TFExample.    \n",
        "      tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "          'image/height': dataset_util.int64_feature(img_height),\n",
        "          'image/width': dataset_util.int64_feature(img_width),\n",
        "          'image/filename': dataset_util.bytes_feature(image_id.encode('utf8')),\n",
        "          'image/source_id': dataset_util.bytes_feature(image_id.encode('utf8')),\n",
        "          'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
        "          'image/format': dataset_util.bytes_feature('jpeg'.encode('utf8')),\n",
        "          'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
        "          'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
        "          'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
        "          'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
        "          'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
        "          'image/object/class/label': dataset_util.int64_list_feature(classes_int),\n",
        "      }))\n",
        "      \n",
        "      writer.write(tf_example.SerializeToString())\n",
        "      print(count, end='')\n",
        "    except ValueError:\n",
        "      print('Invalid example, ignoring.')\n",
        "      pass\n",
        "    except AssertionError:\n",
        "      print('Wrong Dimensions')\n",
        "      pass\n",
        "    except IndexError:\n",
        "      print(\"Index Error\")\n",
        "      pass\n",
        "    except IOError:\n",
        "      print(\"Can't read example, ignoring.\")\n",
        "      pass\n",
        "      \n",
        "  writer.close()\n",
        "  print(\" done\")\n",
        "\n",
        "import glob\n",
        "images = glob.glob(images_dir + '/*/*.jpg')\n",
        "# images = tf.gfile.Glob(images_dir + '/*/*.jpg')\n",
        "# Load the label map we created.\n",
        "label_map = label_map_util.get_label_map_dict(LABEL_MAP_PATH)\n",
        "\n",
        "random.seed(42)\n",
        "random.shuffle(images)\n",
        "num_train = int(0.9 * len(images))\n",
        "train_examples = images[:num_train]\n",
        "val_examples = images[num_train:]\n",
        "create_tf_record(train_examples, label_map, TRAIN_RECORD_PATH)\n",
        "create_tf_record(val_examples, label_map, VAL_RECORD_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OElwZ5IL2z4m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import tarfile\n",
        "\n",
        "import six.moves.urllib as urllib\n",
        "\n",
        "download_base = 'http://download.tensorflow.org/models/object_detection/'\n",
        "model = MODEL_TYPE + '.tar.gz'\n",
        "tmp = '/content/checkpoint.tar.gz'\n",
        "\n",
        "if not (os.path.exists(CHECKPOINT_PATH)):\n",
        "  # Download the checkpoint\n",
        "  opener = urllib.request.URLopener()\n",
        "  opener.retrieve(download_base + model, tmp)\n",
        "\n",
        "  # Extract all the `model.ckpt` files.\n",
        "  with tarfile.open(tmp) as tar:\n",
        "    for member in tar.getmembers():\n",
        "      member.name = os.path.basename(member.name)\n",
        "      if 'model.ckpt' in member.name:\n",
        "        tar.extract(member, path=CHECKPOINT_PATH)\n",
        "\n",
        "  os.remove(tmp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKpM2iPE2z9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "from google.protobuf import text_format\n",
        "\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import label_map_util\n",
        "\n",
        "# pipeline_skeleton = '/content/models/research/object_detection/samples/configs/' + 'ssd_mobilenet_v1_quantized_300x300_coco14_sync' + '.config'\n",
        "pipeline_skeleton = '/content/models/research/object_detection/samples/configs/' + CONFIG_TYPE + '.config'\n",
        "\n",
        "configs = config_util.get_configs_from_pipeline_file(pipeline_skeleton)\n",
        "\n",
        "label_map = label_map_util.get_label_map_dict(LABEL_MAP_PATH)\n",
        "num_classes = len(label_map.keys())\n",
        "meta_arch = configs[\"model\"].WhichOneof(\"model\")\n",
        "\n",
        "# Small batch size\n",
        "\n",
        "override_dict = {\n",
        "  'model.{}.num_classes'.format(meta_arch): num_classes,\n",
        "  'train_config.batch_size': 24,\n",
        "  'train_input_path': TRAIN_RECORD_PATH,\n",
        "  'eval_input_path': VAL_RECORD_PATH,\n",
        "  'train_config.fine_tune_checkpoint': os.path.join(CHECKPOINT_PATH, 'model.ckpt'),\n",
        "  'label_map_path': LABEL_MAP_PATH\n",
        "}\n",
        "\n",
        "configs = config_util.merge_external_params_with_configs(configs, kwargs_dict=override_dict)\n",
        "pipeline_config = config_util.create_pipeline_proto_from_configs(configs)\n",
        "config_util.save_pipeline_config(pipeline_config, '/content')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcJH-vSM3i0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf $OUTPUT_PATH\n",
        "!python -m object_detection.model_main \\\n",
        "    --pipeline_config_path=/content/pipeline.config \\\n",
        "    --model_dir=$OUTPUT_PATH \\\n",
        "    --num_train_steps=$NUM_TRAIN_STEPS \\\n",
        "    --num_eval_steps=100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLhhCkF16hRs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python -m object_detection.model_main \\\n",
        "    --pipeline_config_path=/content/pipeline.config \\\n",
        "    --model_dir=$OUTPUT_PATH \\\n",
        "    --num_train_steps=200 \\\n",
        "    --num_eval_steps=100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsdCm01d3kgU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "import tensorflow\n",
        "regex = re.compile(r\"model\\.ckpt-([0-9]+)\\.index\")\n",
        "numbers = [int(regex.search(f).group(1)) for f in os.listdir(OUTPUT_PATH) if regex.search(f)]\n",
        "TRAINED_CHECKPOINT_PREFIX = os.path.join(OUTPUT_PATH, 'model.ckpt-{}'.format(max(numbers)))\n",
        "\n",
        "print(f'Using {TRAINED_CHECKPOINT_PREFIX}')\n",
        "\n",
        "!rm -rf $EXPORTED_PATH\n",
        "!python -m object_detection.export_inference_graph \\\n",
        "  --pipeline_config_path=/content/pipeline.config \\\n",
        "  --trained_checkpoint_prefix=$TRAINED_CHECKPOINT_PREFIX \\\n",
        "  --output_directory=$EXPORTED_PATH"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5q_FIhr3mOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LABEL_MAP_PATH    = '/content/drive/My Drive/data/label_map.pbtxt'\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "# Use javascipt to take a photo.\n",
        "# def take_photo(filename, quality=0.8):\n",
        "#   js = Javascript('''\n",
        "#     async function takePhoto(quality) {\n",
        "#       const div = document.createElement('div');\n",
        "#       const capture = document.createElement('button');\n",
        "#       capture.textContent = 'Capture';\n",
        "#       div.appendChild(capture);\n",
        "\n",
        "#       const video = document.createElement('video');\n",
        "#       video.style.display = 'block';\n",
        "#       const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "#       document.body.appendChild(div);\n",
        "#       div.appendChild(video);\n",
        "#       video.srcObject = stream;\n",
        "#       await video.play();\n",
        "\n",
        "#       // Resize the output to fit the video element.\n",
        "#       google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "#       // Wait for Capture to be clicked.\n",
        "#       await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "#       const canvas = document.createElement('canvas');\n",
        "#       canvas.width = video.videoWidth;\n",
        "#       canvas.height = video.videoHeight;\n",
        "#       canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "#       stream.getVideoTracks()[0].stop();\n",
        "#       div.remove();\n",
        "#       return canvas.toDataURL('image/jpeg', quality);\n",
        "#     }\n",
        "#     ''')\n",
        "#   display(js)\n",
        "#   data = eval_js('takePhoto({})'.format(quality))\n",
        "#   binary = b64decode(data.split(',')[1])\n",
        "#   with open(filename, 'wb') as f:\n",
        "#     f.write(binary)\n",
        "#   return filename\n",
        "\n",
        "# try:\n",
        "#   take_photo('/content/photo.jpg')\n",
        "# except Exception as err:\n",
        "#   # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "#   # grant the page permission to access it.\n",
        "#   print(str(err))\n",
        "\n",
        "# Use the captured photo to make predictions\n",
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "from PIL import Image as PImage\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "from object_detection.utils import label_map_util\n",
        "\n",
        "# Load the labels\n",
        "category_index = label_map_util.create_category_index_from_labelmap(LABEL_MAP_PATH, use_display_name=True)\n",
        "\n",
        "# Load the model\n",
        "path_to_frozen_graph = os.path.join(EXPORTED_PATH, 'frozen_inference_graph.pb')\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "  od_graph_def = tf.GraphDef()\n",
        "  with tf.gfile.GFile(path_to_frozen_graph, 'rb') as fid:\n",
        "    serialized_graph = fid.read()\n",
        "    od_graph_def.ParseFromString(serialized_graph)\n",
        "    tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "with detection_graph.as_default():\n",
        "  with tf.Session(graph=detection_graph) as sess:\n",
        "    # Definite input and output Tensors for detection_graph\n",
        "    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
        "    # Each box represents a part of the image where a particular object was detected.\n",
        "    detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
        "    # Each score represent how level of confidence for each of the objects.\n",
        "    # Score is shown on the result image, together with the class label.\n",
        "    detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
        "    detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
        "    num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
        "    image = PImage.open('/content/pic_004.jpg')\n",
        "    # the array based representation of the image will be used later in order to prepare the\n",
        "    # result image with boxes and labels on it.\n",
        "    (im_width, im_height) = image.size\n",
        "    image_np = np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)\n",
        "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "    # Actual detection.\n",
        "    (boxes, scores, classes, num) = sess.run(\n",
        "        [detection_boxes, detection_scores, detection_classes, num_detections],\n",
        "        feed_dict={image_tensor: image_np_expanded})\n",
        "    # Visualization of the results of a detection.\n",
        "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np,\n",
        "        np.squeeze(boxes),\n",
        "        np.squeeze(classes).astype(np.int32), \n",
        "        np.squeeze(scores),\n",
        "        category_index,\n",
        "        use_normalized_coordinates=True,\n",
        "        line_thickness=8,\n",
        "        min_score_thresh=.09)\n",
        "    preds = ([category_index.get(i) for i in classes[0]])\n",
        "    print(preds[0]['name'], scores[0][0])\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.imshow(image_np)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVMIxbEMZ3wm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!saved_model_cli show --dir /content/exported/saved_model --tag_set serve --signature_def serving_default"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E91Sr1rlbLRC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tensorflowjs_converter \n",
        "  --input_format=tf_saved_model \\\n",
        "  --output_node_names='detection_boxes,detection_classes,detection_multiclass_scores,detection_scores,num_detections,raw_detection_boxes,raw_detection_scores' \\\n",
        "  --saved_model_tags=serve \\\n",
        "  --output_format=tfjs_graph_model \\\n",
        "  /content/exported/saved_model \\\n",
        "  /content/web_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hs277A1o3pDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tensorflowjs_converter \\\n",
        "  --input_format=tf_frozen_model \\\n",
        "  --output_format=tfjs_graph_model \\\n",
        "  --output_node_names='Postprocessor/ExpandDims_1,Postprocessor/Slice' \\\n",
        "  --quantization_bytes=1 \\\n",
        "  --skip_op_check \\\n",
        "  $EXPORTED_PATH/frozen_inference_graph.pb \\\n",
        "  /content/model_web\n",
        "\n",
        "import json\n",
        "\n",
        "from object_detection.utils.label_map_util import get_label_map_dict\n",
        "\n",
        "label_map = get_label_map_dict(LABEL_MAP_PATH)\n",
        "label_array = [k for k in sorted(label_map, key=label_map.get)]\n",
        "\n",
        "with open(os.path.join('/content/model_web', 'labels.json'), 'w') as f:\n",
        "  json.dump(label_array, f)\n",
        "\n",
        "!cd /content/model_web && zip -r /content/model_web.zip *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNGnJLlF3rP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('/content/model_web.zip') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrUMMKJTzfe_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tensorflowjs_converter \\\n",
        "  --input_format=tf_frozen_model \\\n",
        "  --output_format=tfjs_graph_model \\\n",
        "  --output_node_names='Postprocessor/ExpandDims_1,Postprocessor/Slice' \\\n",
        "  --quantization_bytes=1 \\\n",
        "  --skip_op_check \\\n",
        "  $EXPORTED_PATH/frozen_inference_graph.pb \\\n",
        "  /content/model_web"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz597Etz2Upk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd /content/web_model && zip -r /content/web_model.zip *"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}